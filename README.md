# CS179G_Project
Big data analytics project using Spark 

# After cloning
- git branch *your-branch-name*
- git checkout *your-branch-name*
- git push --set-upstream origin *your-branch-name*

# <spider_name>.py 
- Use spider to crawl data 

# pipelines.py 
- Use Spark to store crawled data inside MySQL / NoSQL database 

# execute 
- scrapy crawl <spider_name> 
